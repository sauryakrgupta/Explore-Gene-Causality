{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DdLUY_ja9MaL"
      },
      "outputs": [],
      "source": [
        "# Step 1: Importing the necessary Library\n",
        "import hashlib\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKz8ATCzbWvN",
        "outputId": "566cc03f-1f0e-449b-9a3d-0b662253bb4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Step2: Mouting the Drive for Dataset accessing\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Loading the datasets\n",
        "ground_truth = pd.read_csv('/content/drive/MyDrive/zenodo_directory/zenodo_directory/data/benchmark_datasets/opentargets_step2.labels', sep='\\t')\n",
        "gene_embedding = pd.read_csv('/content/drive/MyDrive/zenodo_directory/zenodo_directory/data/helper_datasets/gene_embeddings.csv')\n",
        "phenotype = pd.read_csv('/content/drive/MyDrive/zenodo_directory/zenodo_directory/data/benchmark_datasets/opentargets_step2.for_llm.tsv', sep='\\t')\n",
        "phenotype_embedding = pd.read_csv('/content/drive/MyDrive/zenodo_directory/zenodo_directory/data/helper_datasets/phenotype_embeddings.csv')\n",
        "\n",
        "# Step 4: Add row_number to the three specific dataframes\n",
        "ground_truth['row_number'] = ground_truth.index\n",
        "gene_embedding['row_number'] = gene_embedding.index\n",
        "phenotype_embedding['row_number'] = phenotype_embedding.index\n",
        "\n",
        "# Print the column names of each DataFrame\n",
        "print(\"Ground Truth Columns:\\n\", ground_truth.columns)\n",
        "print(\"Gene Embeddings Columns:\\n\", gene_embedding.columns)\n",
        "print(\"Phenotype Embeddings Columns:\\n\", phenotype_embedding.columns)\n",
        "print(\"Phenotype Gene Columns:\\n\", phenotype.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_qLUChreBpEA",
        "outputId": "1c1f5fb2-f0bf-4ce4-a544-ea282bd79141"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth Columns:\n",
            " Index(['symbol', 'gene', 'row_number'], dtype='object')\n",
            "Gene Embeddings Columns:\n",
            " Index(['Unnamed: 0', '0', 'gpt_description', 'embedding', 'row_number'], dtype='object')\n",
            "Phenotype Embeddings Columns:\n",
            " Index(['Unnamed: 0', '0', 'gpt_description', 'embedding', 'row_number'], dtype='object')\n",
            "Phenotype Gene Columns:\n",
            " Index(['row_number', 'description', 'symbol_gene_string',\n",
            "       'ensembl_gene_string'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Merge the phenotype gene data with ground truth labels on 'row_number'\n",
        "merged_df = phenotype.merge(ground_truth, on='row_number', how='left')\n",
        "\n",
        "# Step 6: Merging with gene embeddings and phenotype embedding\n",
        "merged_df = merged_df.merge(gene_embedding[['row_number', 'embedding']], on='row_number', how='left', suffixes=('', '_gene'))\n",
        "\n",
        "merged_df = merged_df.merge(phenotype_embedding[['row_number', 'embedding']], on='row_number', how='left', suffixes=('', '_phenotype'))\n",
        "\n",
        "# Step 7: Clean and prepare the embeddings columns\n",
        "def process_embedding(embedding_str):\n",
        "    if isinstance(embedding_str, str):\n",
        "        return np.array([float(i) for i in embedding_str.strip('[]').split(',')])\n",
        "    return np.nan\n",
        "\n",
        "# Apply processing to the correct columns\n",
        "merged_df['embedding_gene'] = merged_df['embedding'].apply(process_embedding)\n",
        "merged_df['embedding_phenotype'] = merged_df['embedding'].apply(process_embedding)\n",
        "\n",
        "# Step 8: Cosine similarity of Phenotype and Gene embeddings\n",
        "merged_df = merged_df.dropna(subset=['embedding_gene', 'embedding_phenotype'])\n",
        "merged_df['cosine_similarity'] = merged_df.apply(\n",
        "    lambda row: cosine_similarity(row['embedding_gene'].reshape(1, -1), row['embedding_phenotype'].reshape(1, -1))[0][0],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Step 9: Dataframe to include necessary columns\n",
        "result_df = merged_df[['row_number', 'description', 'symbol', 'cosine_similarity']]"
      ],
      "metadata": {
        "id": "szsZON7BDSlN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Hashing name for unique seed\n",
        "name = \"Saurya Kumar Gupta\"\n",
        "hashed_name = hashlib.sha256(name.replace(\" \", \"\").lower().encode()).hexdigest()\n",
        "seed = int(hashed_name, 16) % (2**32)\n",
        "\n",
        "# Step 11: Sampling 500 phenotypes using the seed that generated by name using SHA256\n",
        "np.random.seed(seed)\n",
        "sample = result_df.sample(n=500, random_state=seed)"
      ],
      "metadata": {
        "id": "hSannQ_-FPTT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Saving unique dataset to a new file called sample\n",
        "sample.to_csv('/content/drive/MyDrive/zenodo_directory/zenodo_directory/data/benchmark_datasets/sample.xlsx', index=False)\n",
        "print(\"Unique dataset created and saved as 'sample.xlsx'.\")\n",
        "\n",
        "# Printing the hash value\n",
        "print(f\"Hash value of dataset seed is: {hashed_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVJEiYhEFSFP",
        "outputId": "1d001432-f4ff-4486-d8ab-82b2badd3e68"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique dataset created and saved as 'unique_phenotype_sample.csv'.\n",
            "Hash value of dataset seed is: 41021185ee9be2c95fe2de45f0614dd161a3c4d7eb10f7a1892678f3d6fdc30f\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}